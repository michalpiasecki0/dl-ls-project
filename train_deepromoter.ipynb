{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.deepromoter import DeePromoter\n",
    "from src.utils import load_dataset, protein2num, get_list_kmer\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch\n",
    "import math\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from icecream import ic\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"train_data.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['insert_chrom', 'insert_name', 'sequence', 'rna_dna_ratio',\n",
       "       'is_active'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPER = {\n",
    "    \"A\": 0,\n",
    "    \"C\": 1,\n",
    "    \"G\": 2,\n",
    "    \"T\": 3,\n",
    "}\n",
    "def one_hot_seq(sequences: pd.Series) -> torch.Tensor:\n",
    "    total = []\n",
    "    \n",
    "    for seq in sequences:\n",
    "        x = torch.zeros(size=(4, len(seq)))\n",
    "        for i, aa in enumerate(seq):\n",
    "            x[MAPPER[aa], i] = 1\n",
    "        total.append(x)\n",
    "    return torch.stack(total, dim=0)\n",
    "\n",
    "X = one_hot_seq(data[\"sequence\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"is_active\"]\n",
    "y = torch.tensor(y, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeePromoter(\n",
       "  (pconv): ParallelCNN(\n",
       "    (lseq): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(4, 4, kernel_size=(27,), stride=(1,), padding=same)\n",
       "        (1): ReLU()\n",
       "        (2): MaxPool1d(kernel_size=6, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(4, 4, kernel_size=(14,), stride=(1,), padding=same)\n",
       "        (1): ReLU()\n",
       "        (2): MaxPool1d(kernel_size=6, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(4, 4, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (1): ReLU()\n",
       "        (2): MaxPool1d(kernel_size=6, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bilstm): BidirectionalLSTM(\n",
       "    (rnn): LSTM(12, 12, batch_first=True, bidirectional=True)\n",
       "    (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=540, out_features=540, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=540, out_features=2, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ker = [27, 14, 7]\n",
    "net = DeePromoter(ker, \n",
    "                  input_shape=(32, 271, 4),\n",
    "                  )\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine X and y into a TensorDataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for training and testing sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 'Start training'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 1, loss: 0.633'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 67.16185455852403%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 2, loss: 0.624'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 3, loss: 0.618'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 4, loss: 0.617'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 5, loss: 0.612'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 6, loss: 0.607'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 7, loss: 0.606'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 8, loss: 0.602'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 9, loss: 0.602'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 10, loss: 0.600'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 11, loss: 0.599'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 60.189289565113214%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 12, loss: 0.595'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 13, loss: 0.593'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 14, loss: 0.591'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 15, loss: 0.593'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 16, loss: 0.589'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 17, loss: 0.588'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 18, loss: 0.584'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 19, loss: 0.585'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 20, loss: 0.578'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 21, loss: 0.579'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 54.12723134060141%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 22, loss: 0.577'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 23, loss: 0.576'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 24, loss: 0.575'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 25, loss: 0.571'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 26, loss: 0.569'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 27, loss: 0.567'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 28, loss: 0.565'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 29, loss: 0.560'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 30, loss: 0.557'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 31, loss: 0.554'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 61.231580208458126%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 32, loss: 0.552'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 33, loss: 0.551'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 34, loss: 0.550'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 35, loss: 0.546'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 36, loss: 0.544'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 37, loss: 0.542'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 38, loss: 0.540'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 39, loss: 0.537'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 40, loss: 0.535'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 41, loss: 0.535'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 63.040613394033784%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 42, loss: 0.532'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 43, loss: 0.533'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 44, loss: 0.527'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 45, loss: 0.526'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 46, loss: 0.525'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 47, loss: 0.522'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 48, loss: 0.521'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 49, loss: 0.520'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 50, loss: 0.517'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 51, loss: 0.518'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 60.704444710674494%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 52, loss: 0.515'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 53, loss: 0.516'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 54, loss: 0.511'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 55, loss: 0.510'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 56, loss: 0.508'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 57, loss: 0.510'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 58, loss: 0.506'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 59, loss: 0.504'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 60, loss: 0.504'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 61, loss: 0.505'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 56.52330178507248%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 62, loss: 0.501'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 63, loss: 0.502'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 64, loss: 0.501'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 65, loss: 0.499'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 66, loss: 0.495'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 67, loss: 0.498'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 68, loss: 0.498'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 69, loss: 0.495'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 70, loss: 0.491'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 71, loss: 0.491'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 56.391517910626575%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 72, loss: 0.490'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 73, loss: 0.488'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 74, loss: 0.486'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 75, loss: 0.490'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 76, loss: 0.486'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 77, loss: 0.484'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 78, loss: 0.485'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 79, loss: 0.482'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 80, loss: 0.483'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 81, loss: 0.482'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 57.09835869174554%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 82, loss: 0.482'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 83, loss: 0.480'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 84, loss: 0.482'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 85, loss: 0.480'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 86, loss: 0.480'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 87, loss: 0.476'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 88, loss: 0.473'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 89, loss: 0.476'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 90, loss: 0.478'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 91, loss: 0.475'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 57.33796573619264%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 92, loss: 0.473'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 93, loss: 0.473'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 94, loss: 0.474'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 95, loss: 0.475'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 96, loss: 0.474'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 97, loss: 0.472'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 98, loss: 0.470'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 99, loss: 0.469'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 100, loss: 0.471'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 101, loss: 0.467'\n",
      "ic| f\"Accuracy on test set: {accuracy}%\": 'Accuracy on test set: 55.840421708398225%'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 102, loss: 0.467'\n",
      "ic| f\"Epoch {epoch+1}, loss: {running_loss:.3f}\": 'Epoch 103, loss: 0.467'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# pass model to\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/personal/ml-master/sem-2/dl_ls/project-heidelberg/src/deepromoter.py:100\u001b[0m, in \u001b[0;36mDeePromoter.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpconv(x)\n\u001b[1;32m     99\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbilstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m    102\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/personal/ml-master/sem-2/dl_ls/project-heidelberg/src/deepromoter.py:56\u001b[0m, in \u001b[0;36mBidirectionalLSTM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m:param inputs: visual feature [batch_size x T x input_size]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m:return: contextual feature [batch_size x T x output_size]\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mflatten_parameters()\n\u001b[0;32m---> 56\u001b[0m recurrent, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# batch_size x T x input_size -> batch_size x T x (2*hidden_size)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(recurrent)  \u001b[38;5;66;03m# batch_size x T x output_size\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m(\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1126\u001b[0m         hx,\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[1;32m   1134\u001b[0m     )\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "File \u001b[0;32m~/programmes/miniconda3/envs/ml-base/lib/python3.11/site-packages/torch/_VF.py:28\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf, name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "exp_folder = Path(\"exp\")\n",
    "running_loss = 0\n",
    "best_mcc = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "break_after = 10\n",
    "last_update_best = 0\n",
    "pbar = range(epoch_num)\n",
    "ic(\"Start training\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    running_loss = 0\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        # get the inputs\n",
    "        inputs, labels = X.to(device), y.to(device)\n",
    "        inputs = inputs.permute(0, 2, 1)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # pass model to\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss /= len(train_loader)\n",
    "    ic(f\"Epoch {epoch+1}, loss: {running_loss:.3f}\")\n",
    "    if epoch % 10 == 0:\n",
    "        net.eval()\n",
    "        torch.save(net.state_dict(), str(exp_folder.joinpath(\"epoch_\" + str(epoch) + \".pth\")))\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for test_inputs, test_labels in test_loader:\n",
    "                test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "                test_inputs = test_inputs.permute(0, 2, 1)\n",
    "                test_outputs = net(test_inputs)\n",
    "                _, predicted = torch.max(test_outputs, 1)\n",
    "                total += test_labels.size(0)\n",
    "                correct += (predicted == test_labels.long()).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        ic(f\"Accuracy on test set: {accuracy}%\")\n",
    "        #        precision, recall, MCC = mcc(eval_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
